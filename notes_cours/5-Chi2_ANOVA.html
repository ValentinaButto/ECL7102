<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Tableaux de contingence et ANOVA</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/spacelab.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>
<link href="libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Tableaux de contingence et ANOVA</h1>
<h4 class="date"><br/>23 septembre 2019</h4>

</div>


<div id="plan-general" class="section level1">
<h1>Plan général</h1>
<p>Au dernier cours, nous avons utilisé le test <span class="math inline">\(t\)</span> pour déterminer si la valeur moyenne d’une variable différait entre deux groupes. L’analyse de la variance (ANOVA) dont nous commencerons à discuter aujourd’hui permet d’étendre cette comparaison à plusieurs groupes.</p>
<p>De façon plus générale, nous pourrions dire que le test <span class="math inline">\(t\)</span> et l’ANOVA portent sur l’effet de prédicteurs catégoriels (ex.: différents traitements) sur une réponse numérique. Un autre test que nous utiliserons ce cours-ci est le test du <span class="math inline">\(\chi^2\)</span>, qui vise à détecter une association entre deux variables catégorielles.</p>
<p>Plus tard dans la session, nous nous concentrerons sur les modèles de régression. Ceux-ci ont une portée plus large puisqu’ils permettent de relier une variable réponse à des prédicteurs catégoriels et numériques. En particulier, nous verrons que le test <span class="math inline">\(t\)</span> et l’ANOVA sont des exemples de modèles de régression linéaire.</p>
<table>
<colgroup>
<col width="33%" />
<col width="37%" />
<col width="28%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Réponse catégorielle</th>
<th>Réponse numérique</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Prédicteur catégoriel</td>
<td>Test du <span class="math inline">\(\chi^2\)</span></td>
<td>Test <span class="math inline">\(t\)</span> (2 catégories) ou ANOVA (plus de 2 catégories)</td>
</tr>
<tr class="even">
<td>Prédicteur catégoriel ou numérique</td>
<td>Régression logistique</td>
<td>Régression linéaire</td>
</tr>
</tbody>
</table>
</div>
<div id="objectifs" class="section level1">
<h1>Objectifs</h1>
<ul>
<li><p>Utiliser le test du <span class="math inline">\(\chi^2\)</span> pour comparer les fréquences d’une variable catégorielle à une distribution de référence, ou pour tester l’association entre deux variables catégorielles dans un tableau de contingence.</p></li>
<li><p>Comprendre le principe de l’analyse de la variance et réaliser une ANOVA à un facteur.</p></li>
<li><p>Déterminer les différences significatives entre traitements à partir du test des étendues de Tukey.</p></li>
</ul>
</div>
<div id="comparer-les-frequences-dune-variable-a-une-distribution-de-reference" class="section level1">
<h1>Comparer les fréquences d’une variable à une distribution de référence</h1>
<p><strong>Exemple</strong>: Pour vérifier si un dé est équilibré, nous compilons le résultat de 100 lancers. Le tableau suivant montre le nombre de fois où chaque nombre a été obtenu (sa <em>fréquence</em> <span class="math inline">\(f\)</span>).</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(i\)</span></th>
<th><span class="math inline">\(f_i\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>12</td>
</tr>
<tr class="even">
<td>2</td>
<td>17</td>
</tr>
<tr class="odd">
<td>3</td>
<td>16</td>
</tr>
<tr class="even">
<td>4</td>
<td>18</td>
</tr>
<tr class="odd">
<td>5</td>
<td>11</td>
</tr>
<tr class="even">
<td>6</td>
<td>26</td>
</tr>
<tr class="odd">
<td><strong>Total</strong></td>
<td><strong>100</strong></td>
</tr>
</tbody>
</table>
<p>Notre hypothèse nulle est que le dé est équilibré, donc il y a une probabilité égale d’obtenir chaque valeur (<span class="math inline">\(p_i\)</span> = 1/6 pour <span class="math inline">\(i\)</span> de 1 à 6). Si on multiplie ces probabilités par le nombre total de lancers, on obtient la fréquence attendue (<span class="math inline">\(\hat{f_i}\)</span>) pour chaque nombre.</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(i\)</span></th>
<th><span class="math inline">\(f_i\)</span></th>
<th><span class="math inline">\(p_i\)</span></th>
<th><span class="math inline">\(\hat{f_i}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>12</td>
<td>1/6</td>
<td>16.7</td>
</tr>
<tr class="even">
<td>2</td>
<td>17</td>
<td>1/6</td>
<td>16.7</td>
</tr>
<tr class="odd">
<td>3</td>
<td>16</td>
<td>1/6</td>
<td>16.7</td>
</tr>
<tr class="even">
<td>4</td>
<td>18</td>
<td>1/6</td>
<td>16.7</td>
</tr>
<tr class="odd">
<td>5</td>
<td>11</td>
<td>1/6</td>
<td>16.7</td>
</tr>
<tr class="even">
<td>6</td>
<td>26</td>
<td>1/6</td>
<td>16.7</td>
</tr>
<tr class="odd">
<td><strong>Total</strong></td>
<td><strong>100</strong></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<div id="test-du-chi2-de-pearson" class="section level2">
<h2>Test du <span class="math inline">\(\chi^2\)</span> de Pearson</h2>
<p>Pour une variable avec <span class="math inline">\(k\)</span> catégories, la valeur du <span class="math inline">\(\chi^2\)</span> (khi-carré) est calculée ainsi:</p>
<p><span class="math display">\[ \chi^2 = \sum_{i = 1}^k \frac{(f_i - \hat{f_i})^2}{\hat{f_i}} \]</span></p>
<p>La statistique <span class="math inline">\(\chi^2\)</span> mesure donc la somme des déviations entre les fréquences observées et attendues (normalisées par la valeur attendue). Lorsque les <span class="math inline">\(\hat{f_i}\)</span> pour chaque catégorie sont assez grandes (typiquement, 5 ou plus), cette statistique suit approximativement une distribution <span class="math inline">\(\chi^2_{k-1}\)</span>, où <span class="math inline">\(k - 1\)</span> est le nombre de degrés de liberté.</p>
<p><strong>Rappel</strong>: Le nombre de degrés de liberté correspond au nombre de valeurs indépendantes utilisées pour le calcul d’une statistique. Ici, le <span class="math inline">\(\chi^2\)</span> est calculé à partir des déviations entre fréquence observée et fréquence attendue pour <span class="math inline">\(k\)</span> catégories. Toutefois, puisque la somme des déviations doit être égale à 0 (car le total des <span class="math inline">\(f_i\)</span> et des <span class="math inline">\(\hat{f_i}\)</span> est le même) il y a <span class="math inline">\(k - 1\)</span> déviations indépendantes.</p>
<p><span class="math display">\[ \sum_{i=1}^k f_i = \sum_{i=1}^k \hat{f_i} \]</span>, donc <span class="math display">\[\sum_{i=1}^k (f_i - \hat{f_i}) = 0\]</span></p>
<p>Voici la distribution <span class="math inline">\(\chi^2_{k}\)</span> pour différentes valeurs de <span class="math inline">\(k\)</span>:</p>
<p><img src="../images/khi_carre.png" /></p>
<p>Dans R, la fonction <code>pchisq(q, df)</code> donne la probabilité d’obtenir une valeur inférieure ou égale à <span class="math inline">\(q\)</span> pour une distribution <span class="math inline">\(\chi^2\)</span> avec <span class="math inline">\(df\)</span> degrés de liberté. Calculons cette probabilité pour notre exemple.</p>
<pre class="r"><code># Données
x &lt;- c(12, 17, 16, 18, 11, 26)
n &lt;- sum(x) # total

# Probabilités théoriques
p &lt;- rep(1/6, 6)

# Calcul du khi2
khi2 &lt;- sum((x - n*p)^2 / (n*p))
khi2</code></pre>
<pre><code>## [1] 8.6</code></pre>
<pre class="r"><code>pchisq(khi2, df = 5)</code></pre>
<pre><code>## [1] 0.8738776</code></pre>
<p><strong>Question</strong>: Quelle est la valeur <span class="math inline">\(p\)</span> pour ce test? S’agit-il d’un test unilatéral ou bilatéral?</p>
<p>Il s’agit d’un test unilatéral, puisque si le modèle théorique n’est pas bon, la somme des déviations sera plus grande que prévue. La valeur <span class="math inline">\(p\)</span> est <code>1 - pchisq(khi2, df = 5)</code> soit environ 0.126.</p>
<p>Plutôt que de calculer manuellement la statistique, nous pouvons utiliser la fonction <code>chisq.test</code>.</p>
<pre class="r"><code>chisq.test(x, p = p)</code></pre>
<pre><code>## 
##  Chi-squared test for given probabilities
## 
## data:  x
## X-squared = 8.6, df = 5, p-value = 0.1261</code></pre>
</div>
</div>
<div id="test-dassociation-entre-deux-variables-categorielles" class="section level1">
<h1>Test d’association entre deux variables catégorielles</h1>
<div id="tableau-de-contingence" class="section level2">
<h2>Tableau de contingence</h2>
<p>Souvent, nous n’avons pas de distribution de référence pour une variable catégorielle, mais nous voulons vérifier si sa distribution dépend de la valeur d’une autre variable catégorielle, autrement dit, s’il existe une <em>association</em> entre les deux variables.</p>
<p>Par exemple, supposons qu’on ait compté le nombre d’arbres morts et vivants de trois espèces de conifères (ABBA: sapin baumier; PIGL: épinette blanche; PIMA: épinette noire) dans une placette suite à une épidémie de tordeuse des bourgeons de l’épinette.</p>
<pre class="r"><code># rbind crée une matrice en rattachant des vecteurs par rangée
survie &lt;- rbind(c(29, 11, 12), c(31, 29, 38)) 
rownames(survie) &lt;- c(&quot;mort&quot;, &quot;vivant&quot;)
colnames(survie) &lt;- c(&quot;ABBA&quot;, &quot;PIGL&quot;, &quot;PIMA&quot;)
survie</code></pre>
<pre><code>##        ABBA PIGL PIMA
## mort     29   11   12
## vivant   31   29   38</code></pre>
<p>Ce type de matrice se nomme un <strong>tableau de contingence</strong>.</p>
<p>Dans notre exemple, les deux variables (survie et espèce) sont associées si le taux de mortalité dépend de l’espèce. L’hypothèse nulle représente l’absence d’association, c’est-à-dire que la survie est <em>indépendante</em> de l’espèce.</p>
</div>
<div id="test-du-chi2-pour-deux-variables" class="section level2">
<h2>Test du <span class="math inline">\(\chi^2\)</span> pour deux variables</h2>
<p>Comme dans la section précédente, nous calculerons le <span class="math inline">\(\chi^2\)</span> à partir des déviations entre les fréquences observées (<span class="math inline">\(f_{ij}\)</span>) et attendues (<span class="math inline">\(\hat{f_{ij}}\)</span>).</p>
<p><span class="math display">\[ \chi^2 = \sum_{i = 1}^r \sum_{j = 1}^c \frac{(f_{ij} - \hat{f_{ij}})^2}{\hat{f_{ij}}} \]</span></p>
<p>Ici, <span class="math inline">\(r\)</span> et <span class="math inline">\(c\)</span> réfèrent au nombre de rangées et de colonnes du tableau, respectivement.</p>
<p>Comment déterminer les fréquences attendues <span class="math inline">\(\hat{f_{ij}}\)</span>? Calculons d’abord le total des observations dans chaque rangée et colonne, ainsi que le grand total.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>ABBA</th>
<th>PIGL</th>
<th>PIMA</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>mort</td>
<td>29</td>
<td>11</td>
<td>12</td>
<td>52</td>
</tr>
<tr class="even">
<td>vivant</td>
<td>31</td>
<td>29</td>
<td>38</td>
<td>98</td>
</tr>
<tr class="odd">
<td>Total</td>
<td>60</td>
<td>40</td>
<td>50</td>
<td>150</td>
</tr>
</tbody>
</table>
<p>Notons le total de la rangée <span class="math inline">\(i\)</span> par <span class="math inline">\(N_i\)</span>, le total de la colonne <span class="math inline">\(j\)</span> par <span class="math inline">\(N_j\)</span> et le grand total par <span class="math inline">\(N\)</span>. Nous estimons la probabilité de chaque catégorie par la proportion du grand total compris dans cette catégorie: <span class="math inline">\(\hat{p_i} = N_i / N\)</span> et <span class="math inline">\(\hat{p_j} = N_j / N\)</span>.</p>
<p>La probabilité conjointe de deux variables indépendantes est le produit des probabilités des variables prises séparément, ex.: (prob. que l’arbre est un sapin vivant) = (prob. que l’arbre est un sapin) x (prob. que l’arbre est vivant). Ainsi, les fréquences attendues d’après l’hypothèse nulle sont calculées comme suit.</p>
<p><span class="math display">\[ \hat{f_{ij}} = N p_i p_j = \frac{N_i N_j}{N}\]</span></p>
<p>Si l’hypothèse nulle est exacte, la statistique <span class="math inline">\(\chi^2\)</span> suit alors une distribution avec <span class="math inline">\((r - 1) \times (c - 1)\)</span> degrés de libertés. Dans notre exemple, <span class="math inline">\(df = 2\)</span>. En effet, puisque les fréquences attendues sont basées sur les totaux de chaque rangée et de chaque colonne, la somme des déviations dans chaque rangée et chaque colonne doit être zéro.</p>
<p>Si nous choisissons un seuil <span class="math inline">\(\alpha = 0.05\)</span> puis que nous appliquons la fonction <code>chisq.test</code> à cette matrice, nous obtenons une valeur <span class="math inline">\(p\)</span> de 0.01, signifiant la présence d’une association significative entre les deux variables.</p>
<pre class="r"><code>chisq.test(survie)</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  survie
## X-squared = 8.3669, df = 2, p-value = 0.01525</code></pre>
<p>Pour préciser la nature de cette association, nous pouvons assigner le résultat du test à une variable <code>khi2</code> et inspecter les fréquences attendues (<code>khi2$expected</code>) ainsi que les résidus (<code>khi2$residuals</code>).</p>
<pre class="r"><code>khi2 &lt;- chisq.test(survie)
khi2$expected</code></pre>
<pre><code>##        ABBA     PIGL     PIMA
## mort   20.8 13.86667 17.33333
## vivant 39.2 26.13333 32.66667</code></pre>
<pre class="r"><code>khi2$residuals</code></pre>
<pre><code>##             ABBA       PIGL       PIMA
## mort    1.797969 -0.7698235 -1.2810252
## vivant -1.309697  0.5607636  0.9331389</code></pre>
<p>Les résidus correspondent aux déviations normalisées:</p>
<p><span class="math display">\[ \frac{f_{ij} - \hat{f_{ij}}}{\sqrt{\hat{f_{ij}}}} \]</span></p>
<p>La somme du carré de ces déviations correspond au <span class="math inline">\(\chi^2\)</span>.</p>
<p>Comment pouvons-nous interpréter cette matrice de résidus? Puisqu’il y a un excès de sapins morts (résidu positif), le taux de mortalité des sapins est plus élevé que prévu par l’hypothèse nulle, tandis qu’il est plus faible que prévu pour les deux épinettes.</p>
<p>Toutefois, le rejet de l’hypothèse nulle (indépendance entre la mortalité et l’espèce) au niveau du tableau ne nous dit pas entre quelles espèces le taux de mortalité varie significativement. Plus tard cette session, nous verrons comment une régression logistique permet d’estimer la probabilité d’un résultat binaire (ex.: survie) en fonction de catégories ou d’une variable continue.</p>
</div>
<div id="notes-sur-lutilisation-des-tests-du-chi2" class="section level2">
<h2>Notes sur l’utilisation des tests du <span class="math inline">\(\chi^2\)</span></h2>
<ul>
<li><p>Le test du <span class="math inline">\(\chi^2\)</span> doit toujours être réalisé sur les fréquences (nombre d’observations), pas sur les proportions. Sans connaître la taille de l’échantillon, les proportions elles-mêmes ne nous disent pas si une déviation est significative. Par exemple, si deux catégories devraient se trouver en proportions égales (50%/50%), des fréquences de 60 et 40 peuvent constituer une déviation significative, mais pas des fréquences de 6 et 4.</p></li>
<li><p>Puisque le test du <span class="math inline">\(\chi^2\)</span> approxime des données discrètes à partir d’une distribution continue, il devient moins exact à mesure que la taille de l’échantillon diminue. Le test n’est donc pas recommandé si une des fréquences attendues (<span class="math inline">\(\hat{f_{ij}}\)</span>) est inférieure à 5. Dans ce cas, on peut utiliser le test de Fisher (fonction <code>fisher.test</code> dans R) qui calcule les probabilités exactes de différents tableaux de contingence en supposant que les totaux par rangée et colonne sont fixes.</p></li>
</ul>
<pre class="r"><code>tab &lt;- matrix(c(4, 6, 8, 2), nrow = 2)
tab</code></pre>
<pre><code>##      [,1] [,2]
## [1,]    4    8
## [2,]    6    2</code></pre>
<pre class="r"><code>chisq.test(tab)</code></pre>
<pre><code>## Warning in chisq.test(tab): Chi-squared approximation may be incorrect</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test with Yates&#39; continuity correction
## 
## data:  tab
## X-squared = 1.875, df = 1, p-value = 0.1709</code></pre>
<pre class="r"><code>fisher.test(tab)</code></pre>
<pre><code>## 
##  Fisher&#39;s Exact Test for Count Data
## 
## data:  tab
## p-value = 0.1698
## alternative hypothesis: true odds ratio is not equal to 1
## 95 percent confidence interval:
##  0.01252647 1.65925396
## sample estimates:
## odds ratio 
##  0.1841181</code></pre>
</div>
</div>
<div id="analyse-de-la-variance-anova" class="section level1">
<h1>Analyse de la variance (ANOVA)</h1>
<p>Supposons que nous souhaitons comparer la moyenne d’une variable entre plusieurs (&gt;2) groupes. Nous pourrions comparer les groupes deux à deux avec un test <span class="math inline">\(t\)</span> (par exemple, A-B, B-C et A-C pour trois groupes), mais comme nous avons vu lors du dernier cours, effectuer plusieurs tests augmente la probabilité de commettre une erreur de type I.</p>
<p>Pour un échantillon divisé en plusieurs groupes, l’analyse de la variance (ANOVA) compare la variation entre observations à l’intérieur de chaque groupe à la variation entre les groupes. Elle permet donc de tester globalement l’hypothèse nulle selon laquelle les observations de chaque groupe proviennent de populations avec la même moyenne.</p>
<p>Comme exemple, prenons les 10 premières observations de chaque espèce dans le jeu de données <code>iris</code> inclus avec R. Voici la distribution de la largeur des sépales pour cet échantillon.</p>
<pre class="r"><code>iris_ech &lt;- iris[c(1:10, 51:60, 101:110), ]
ggplot(iris_ech, aes(x = Species, y = Sepal.Width)) +
    geom_boxplot()</code></pre>
<p><img src="5-Chi2_ANOVA_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Ce graphique montre la variation d’une variable numérique en fonction d’une variable catégorielle (ou facteur) qui comporte trois catégories.</p>
<div id="modele-danova-a-un-facteur" class="section level2">
<h2>Modèle d’ANOVA à un facteur</h2>
<p>Supposons que nous mesurons la variable <span class="math inline">\(y\)</span> pour <span class="math inline">\(l\)</span> groupes comprenant chacun <span class="math inline">\(n\)</span> observations. La différence entre une observation <span class="math inline">\(k\)</span> du groupe <span class="math inline">\(i\)</span> (<span class="math inline">\(y_{ik}\)</span>) et la moyenne (théorique) de ce groupe (<span class="math inline">\(\mu_i\)</span>) est le résidu <span class="math inline">\(\epsilon_{ik}\)</span>.</p>
<p><span class="math display">\[ y_{ik} = \mu_i + \epsilon_{ik} \]</span></p>
<p>Dans le modèle d’ANOVA, nous supposons que les résidus sont distribués normalement avec une moyenne de 0 et une écart-type fixe.</p>
<p><span class="math display">\[ \epsilon_{ik} \sim N(0, \sigma) \]</span></p>
<p>L’hypothèse nulle est que <span class="math inline">\(\mu_i\)</span> est la même pour tous les groupes. Nous pouvons aussi représenter le même modèle en fonction de la moyenne globale <span class="math inline">\(\mu\)</span> et de la déviation <span class="math inline">\(\alpha_i\)</span> de la moyenne du groupe <span class="math inline">\(i\)</span> par rapport à <span class="math inline">\(\mu\)</span>.</p>
<p><span class="math display">\[ y_{ik} = \mu + \alpha_i + \epsilon_{ik} \]</span></p>
</div>
<div id="somme-des-ecarts-au-carre" class="section level2">
<h2>Somme des écarts au carré</h2>
<p>Si <span class="math inline">\(\bar{y}\)</span> est la moyenne globale des observations de <span class="math inline">\(y\)</span> et <span class="math inline">\(\bar{y_i}\)</span> est la moyenne des observations du groupe <span class="math inline">\(i\)</span>, alors il est possible de démontrer la relation suivante impliquant la somme des écarts au carré (<em>sum of squares</em>).</p>
<p><span class="math display">\[ \sum_{i = 1}^l \sum_{k = i}^n (y_{ik} - \bar{y})^2 = \sum_{i = 1}^l \sum_{k = i}^n (y_{ik} - \bar{y_i})^2 + \sum_{i = 1}^l \sum_{k = i}^n (\bar{y_i} - \bar{y})^2 \]</span></p>
<p>Puisque le dernier terme ne dépend pas de <span class="math inline">\(k\)</span>, on peut ré-écrire l’équation:</p>
<p><span class="math display">\[ \sum_{i = 1}^l \sum_{k = i}^n (y_{ik} - \bar{y})^2 = \sum_{i = 1}^l \sum_{k = i}^n (y_{ik} - \bar{y_i})^2 + \sum_{i = 1}^l n (\bar{y_i} - \bar{y})^2 \]</span></p>
<p>Le terme à gauche est la somme des carrés de l’écart total (<em>SST</em>, pour <em>total sum of squares</em>), le premier terme à droite est la somme des carrés de l’écart résiduel ou erreur (<em>SSE</em>, pour <em>error sum of squares</em>) et le deuxième terme à droite est la somme des carrés de l’écart entre les groupes associés au facteur A (<em>SSA</em>, le seul facteur dans ce cas-ci).</p>
<p>On obtient donc l’équation <em>SST = SSE + SSA</em>, qui décompose l’écart total en deux composantes: l’une due aux écarts observés à l’intérieur de chaque groupe (SSE) et l’autre due aux écarts observés entre les groupes (SSA).</p>
</div>
<div id="tableau-danalyse-de-la-variance" class="section level2">
<h2>Tableau d’analyse de la variance</h2>
<p>À partir des sommes des écarts au carré vues ci-dessus, on peut calculer les écarts au carré moyens (<em>MS</em>, pour <em>mean square</em>) en divisant chaque somme par le nombre approprié de degrés de liberté.</p>
<ul>
<li><p>Pour l’écart à la moyenne total, il y a <span class="math inline">\(nl - 1\)</span> degrés de liberté; puisque la somme des écarts est zéro, le dernier n’est pas indépendant.</p></li>
<li><p>Pour l’écart résiduel, il y a <span class="math inline">\((n-1)l\)</span> degrés de liberté, car il y a <span class="math inline">\(n-1\)</span> écarts indépendants par groupe.</p></li>
<li><p>Pour l’écart entre la moyenne des groupes et la moyenne globale, il y a <span class="math inline">\(l - 1\)</span> degrés de liberté.</p></li>
</ul>
<p>Notez que la somme des degrés de liberté est la même des deux côtés de l’équation: <span class="math inline">\(nl - 1 = (n-1)l + (l - 1)\)</span>.</p>
<p>La somme des écarts au carré, les degrés de liberté et les écarts au carré moyens peuvent être présentés dans un tableau d’ANOVA.</p>
<table style="width:100%;">
<colgroup>
<col width="5%" />
<col width="31%" />
<col width="31%" />
<col width="31%" />
</colgroup>
<thead>
<tr class="header">
<th>Composante</th>
<th>Somme des carrés (SS)</th>
<th>Degrés de liberté (df)</th>
<th>Carré moyen (MS)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Facteur A</td>
<td><span class="math inline">\(SSA = \sum_{i = 1}^l n (\bar{y_i} - \bar{y})^2\)</span></td>
<td><span class="math inline">\(l - 1\)</span></td>
<td><span class="math inline">\(MSA = \frac{SSA}{l - 1}\)</span></td>
</tr>
<tr class="even">
<td>Résidu</td>
<td><span class="math inline">\(SSE = \sum_{i = 1}^l \sum_{k = i}^n (y_{ik} - \bar{y_i})^2\)</span></td>
<td><span class="math inline">\((n-1)l\)</span></td>
<td><span class="math inline">\(MSE = \frac{SSE}{(n-1)l}\)</span></td>
</tr>
<tr class="odd">
<td>Total</td>
<td><span class="math inline">\(SST = \sum_{i = 1}^l \sum_{k = i}^n (y_{ik} - \bar{y})^2\)</span></td>
<td><span class="math inline">\(nl - 1\)</span></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div id="test-de-lhypothese-nulle" class="section level2">
<h2>Test de l’hypothèse nulle</h2>
<p>Rappelons la forme du modèle d’ANOVA à un facteur:</p>
<p><span class="math display">\[ y_{ik} = \mu + \alpha_i + \epsilon_{ik} \]</span></p>
<p><span class="math display">\[ \epsilon_{ik} \sim N(0, \sigma) \]</span></p>
<p>La moyenne du carré des résidus (<em>MSE</em>) est un estimateur de la variance du modèle (<span class="math inline">\(\sigma^2\)</span>).</p>
<p>Si l’hypothèse nulle est exacte et qu’il n’y a pas de différence systématique entre les groupes (autrement dit, tous les <span class="math inline">\(\alpha_i\)</span> sont égaux à 0 dans le modèle), alors la moyenne du carré des différences de groupe (<em>MSA</em>) est aussi un estimateur de <span class="math inline">\(\sigma^2\)</span>. En effet, selon l’hypothèse nulle, les différents groupes sont des échantillons indépendants de la même population. Dans ce cas, le terme <em>MSA</em> correspond à la variance de <span class="math inline">\(\bar{y_i}\)</span> multipliée par <span class="math inline">\(n\)</span> (le nombre d’observations par groupe). La variance d’une moyenne de <span class="math inline">\(n\)</span> observations est justement égale à <span class="math inline">\(\sigma^2 / n\)</span>, où <span class="math inline">\(\sigma^2\)</span> est la variance des observations individuelles.</p>
<p>Si <em>MSA</em> et <em>MSE</em> sont deux estimateurs de la même variance selon l’hypothèse nulle, alors leur ratio <span class="math inline">\(F = MSA / MSE\)</span> suit la distribution <span class="math inline">\(F\)</span>. Cette distribution comporte deux paramètres (<span class="math inline">\(d_1\)</span> et <span class="math inline">\(d_2\)</span>) correspondant aux degrés de liberté de <em>MSA</em> et <em>MSE</em>.</p>
<p><img src="../images/distr_f.png" /></p>
<p>En contrepartie, si l’hypothèse nulle est fausse, on s’attend à ce que la valeur de <em>MSA</em> soit plus élevée par rapport à <em>MSE</em>, puisque les différences systématiques entre groupes s’ajouteront aux variations aléatoires de l’échantillonnage. Il s’agit donc d’un test unilatéral: la valeur <span class="math inline">\(p\)</span> est la probabilité d’un ratio <span class="math inline">\(F\)</span> égal ou supérieur à celui observé dans nos données.</p>
</div>
<div id="suppositions-du-modele-danova" class="section level2">
<h2>Suppositions du modèle d’ANOVA</h2>
<p>Pour que le modèle sur lequel est basé l’ANOVA soit valide, les résidus doivent être (1) indépendants entre les observations et suivre (2) une distribution normale avec (3) la même variance <span class="math inline">\(\sigma^2\)</span> dans chaque groupe.</p>
<ul>
<li><p>L’indépendance des résidus signifie notamment que les facteurs non-mesurés qui influencent la réponse sont distribués de façon similaire pour chaque groupe. Pour un plan expérimental, l’assignation aléatoire des traitements aide à assurer cette indépendance.</p></li>
<li><p>Comme le test <span class="math inline">\(t\)</span>, l’ANOVA tolère bien des déviations faibles à modérées par rapport à la distribution normale.</p></li>
<li><p>Contrairement au test <span class="math inline">\(t\)</span>, l’égalité des variances entre groupes (<strong>homoscédasticité</strong>) est essentielle pour l’ANOVA. Si cette supposition n’est pas respectée, il faut transformer les données ou avoir recours à un modèle plus complexe, comme nous verrons plus loin.</p></li>
</ul>
<p>Les calculs présentés plus haut s’appliquent seulement à un échantillon <strong>équilibré</strong>, c’est-à-dire que le nombre d’observations est le même dans chaque groupe. Pour le cours d’aujourd’hui, nous nous limiterons aux échantillons équilibrés. Afin de réaliser une ANOVA non-équilibrée dans R, il faut faire appel aux méthodes de régression linéaire que nous verrons lors des prochains cours.</p>
</div>
</div>
<div id="exemples-danova-a-un-facteur" class="section level1">
<h1>Exemples d’ANOVA à un facteur</h1>
<p>Avec la fonction <code>aov</code> dans R, réalisons une ANOVA de la largeur des sépales en fonction de l’espèce d’iris, à partir de l’échantillon du jeu de données <code>iris</code> choisi au début de cette section.</p>
<pre class="r"><code>anova1 &lt;- aov(Sepal.Width ~ Species, data = iris_ech) 
summary(anova1)</code></pre>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)  
## Species      2  1.118  0.5590   5.179 0.0125 *
## Residuals   27  2.914  0.1079                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>La fonction <code>aov</code> requiert une description du modèle avec la formule <code>reponse ~ predicteur</code>, ainsi que le nom du tableau de données contenant ces variables (argument <code>data</code>). En appliquant la fonction <code>summary</code> au résultat d’une ANOVA, on obtient le tableau d’ANOVA tel que présenté plus haut, en plus de valeur de la statistique <span class="math inline">\(F\)</span> et sa valeur <span class="math inline">\(p\)</span> (<code>Pr(&gt;F)</code>). Avec un seuil de 0.05, l’hypothèse nulle que les espèces ont la même largeur moyenne des sépales serait rejetée.</p>
<p>Pour vérifier que nos données sont conformes aux suppositions du modèle, nous devons consulter les graphiques de diagnostic, obtenus en appliquant la fonction <code>plot</code> au résultat.</p>
<pre class="r"><code>plot(anova1)</code></pre>
<p><img src="5-Chi2_ANOVA_files/figure-html/unnamed-chunk-9-1.png" width="672" /><img src="5-Chi2_ANOVA_files/figure-html/unnamed-chunk-9-2.png" width="672" /><img src="5-Chi2_ANOVA_files/figure-html/unnamed-chunk-9-3.png" width="672" /><img src="5-Chi2_ANOVA_files/figure-html/unnamed-chunk-9-4.png" width="672" /></p>
<p>Les deux premiers graphiques sont les plus importants ici. Le graphique <code>Residuals vs. Fitted</code> montre la valeur des résidus en fonction de la moyenne estimée pour chaque groupe; si le modèle est valide, il ne devrait pas y avoir de tendance visible et les résidus des différents groupes devraient avoir une variance similaire autour de zéro, ce qui est le cas ici. Le deuxième graphique est un diagramme quantile-quantile pour vérifier si les résidus suivent approximativement une distribution normale.</p>
<p>Pour afficher les moyennes par groupe, il faut faire appel à la fonction <code>coef</code> (pour coefficients).</p>
<pre class="r"><code>coef(anova1)</code></pre>
<pre><code>##       (Intercept) Speciesversicolor  Speciesvirginica 
##              3.31             -0.44             -0.37</code></pre>
<p>Par défaut, le terme <code>(Intercept)</code> est la moyenne du premier groupe (ici, l’espèce <em>setosa</em>), tandis que les autres coefficients indiquent la différence entre les autres groupes et cette première moyenne. La moyenne de l’espèce <em>versicolor</em> est 3.31 - 0.44 = 2.87 tandis que la moyenne de l’espèce <em>virginica</em> est 3.31 - 0.37 = 2.94. Le résultat ne nous dit pas lesquelles de ces différences sont significatives.</p>
<p>S’il n’y a que deux groupes, l’ANOVA est équivalente à un test <span class="math inline">\(t\)</span> entre deux échantillons à variance égale.</p>
<pre class="r"><code>library(dplyr)
iris_2sp &lt;- filter(iris_ech, Species != &quot;setosa&quot;)
anova2 &lt;- aov(Sepal.Width ~ Species, data = iris_2sp)
summary(anova2)</code></pre>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)
## Species      1 0.0245  0.0245   0.214   0.65
## Residuals   18 2.0650  0.1147</code></pre>
<pre class="r"><code>coef(anova2)</code></pre>
<pre><code>##      (Intercept) Speciesvirginica 
##             2.87             0.07</code></pre>
<pre class="r"><code>t.test(Sepal.Width ~ Species, data = iris_2sp, var.equal = TRUE)</code></pre>
<pre><code>## 
##  Two Sample t-test
## 
## data:  Sepal.Width by Species
## t = -0.46212, df = 18, p-value = 0.6495
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.3882356  0.2482356
## sample estimates:
## mean in group versicolor  mean in group virginica 
##                     2.87                     2.94</code></pre>
<p>La valeur <span class="math inline">\(p\)</span> et l’estimation des moyennes par espèce sont les mêmes pour les deux tests.</p>
<p>Prenons maintenant le tableau de données <code>InsectSprays</code> qui décrit le nombre d’insectes (<code>count</code>) sur des placettes traitées avec différents insecticides (<code>spray</code>).</p>
<pre class="r"><code>ggplot(InsectSprays, aes(x = spray, y = count)) + 
    geom_boxplot()</code></pre>
<p><img src="5-Chi2_ANOVA_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Avant de regarder les résultats de l’ANOVA, inspectons les deux premiers graphiques de diagnostic.</p>
<pre class="r"><code>anova3 &lt;- aov(count ~ spray, InsectSprays)
plot(anova3, which = 1:2)</code></pre>
<p><img src="5-Chi2_ANOVA_files/figure-html/unnamed-chunk-13-1.png" width="672" /><img src="5-Chi2_ANOVA_files/figure-html/unnamed-chunk-13-2.png" width="672" /></p>
<p>Le graphique des résidus vs. valeurs estimées montre que la variance des résidus est plus élevée pour les groupes où la moyenne est plus élevée, ce qui contredit la supposition de variance égale. Lorsque cela se produit, la distribution des résidus diffère aussi de la normale, comme on voit sur le diagramme quantile-quantile.</p>
<div id="transformation-racine-carree" class="section level2">
<h2>Transformation racine carrée</h2>
<p>L’augmentation de la variance des groupes en fonction de leur moyenne est une caractéristique assez commune des données de comptage (dans l’exemple précédent, il s’agissait du nombre d’insectes). Pour ce type de données, prendre la racine carrée (<code>sqrt</code>) de la variable originale peut rendre les variances plus homogènes. Notez qu’une transformation logarithmique n’est pas possible lorsque les données incluent des 0.</p>
<pre class="r"><code>anova3_racine &lt;- aov(sqrt(count) ~ spray, InsectSprays)
plot(anova3_racine, which = 1:2)</code></pre>
<p><img src="5-Chi2_ANOVA_files/figure-html/unnamed-chunk-14-1.png" width="672" /><img src="5-Chi2_ANOVA_files/figure-html/unnamed-chunk-14-2.png" width="672" /></p>
<pre class="r"><code>summary(anova3_racine)</code></pre>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)    
## spray        5  88.44  17.688    44.8 &lt;2e-16 ***
## Residuals   66  26.06   0.395                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Au lieu de transformer la variable réponse (le nombre d’insectes), une autre option serait de choisir un modèle qui n’est pas basé sur une distribution normale des résidus. C’est l’approche des modèles linéaires généralisés que nous verrons plus tard cette session.</p>
</div>
</div>
<div id="comparaisons-multiples-entre-les-groupes" class="section level1">
<h1>Comparaisons multiples entre les groupes</h1>
<p>Tel que nous avons vu ci-dessus, le rejet de l’hypothèse nulle de l’ANOVA indique qu’il est improbable que tous les groupes aient la même moyenne, mais ne nous dit pas quels groupes ont des moyennes significativement différentes l’une de l’autre.</p>
<p>Le test des étendues de Tukey est conçu pour être utilisé dans ce scénario. Ce test compare les groupes deux à deux avec une statistique basée sur la distribution <span class="math inline">\(t\)</span>, mais qui tient compte des comparaisons multiples pour assurer une probabilité d’erreur de type I inférieure au seuil voulu (habituellement, 5%) sur l’ensemble des comparaisons.</p>
<p>Ce test est implémenté dans R par la fonction <code>TukeyHSD</code> (pour Honest Significant Difference). Par exemple, appliquons le test de Tukey au résultat de notre premier exemple d’ANOVA, sur la variation de la largeur des sépales par espèce d’iris.</p>
<pre class="r"><code>anova1 &lt;- aov(Sepal.Width ~ Species, data = iris_ech) 
tukey1 &lt;- TukeyHSD(anova1)
tukey1</code></pre>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = Sepal.Width ~ Species, data = iris_ech)
## 
## $Species
##                       diff        lwr          upr     p adj
## versicolor-setosa    -0.44 -0.8042735 -0.075726495 0.0155401
## virginica-setosa     -0.37 -0.7342735 -0.005726495 0.0459626
## virginica-versicolor  0.07 -0.2942735  0.434273505 0.8829240</code></pre>
<p>Il semble donc y avoir une différence significative entre <em>setosa</em> et les deux autres espèces.</p>
<p>La fonction <code>plot</code> présente un graphique des intervalles de confiance du test de Tukey.</p>
<pre class="r"><code>plot(tukey1)</code></pre>
<p><img src="5-Chi2_ANOVA_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>Puisque cette méthode vise une probabilité d’erreur de type I de 5% pour l’ensemble des comparaisons, chacune des comparaisons individuelles doit avoir un <span class="math inline">\(\alpha\)</span> &lt; 0.05. Dans ce cas, la probabilité d’erreur de type II (ne pas détecter une différence significative) augmente. On peut donc contrôler le taux d’erreur de type I dans un problème de comparaisons multiples, mais au prix de diminuer la puissance du test lorsque le nombre de comparaisons à faire augmente. Puisque l’ANOVA a une plus grande puissance que des comparaisons multiples, il est même possible qu’aucune des différences entre deux groupes ne soit significative même si l’hypothèse nulle de l’ANOVA a été rejetée.</p>
</div>
<div id="resume" class="section level1">
<h1>Résumé</h1>
<div id="test-du-chi2" class="section level3">
<h3>Test du <span class="math inline">\(\chi^2\)</span></h3>
<ul>
<li><p>Un tableau de contingence est une tabulation croisée du nombre observations (fréquences) selon deux variables catégorielles.</p></li>
<li><p>Le test du <span class="math inline">\(\chi^2\)</span> sert à comparer les fréquences d’une variable catégorielle à une distribution de référence, ou à vérifier l’indépendance de deux variables catégorielles dans un tableau de contingence.</p></li>
<li><p>Lorsque les fréquences attendues sont très faibles (&lt; 5), il faut remplacer l’approximation du <span class="math inline">\(\chi^2\)</span> par un test comptant les probabilités exactes des tableaux de contingence, comme le test de Fisher.</p></li>
</ul>
</div>
<div id="anova" class="section level3">
<h3>ANOVA</h3>
<ul>
<li><p>L’analyse de la variance vise à déterminer si des échantillons provenant de différents groupes (ex.: traitements) sont distribués avec la même moyenne.</p></li>
<li><p>Elle suppose que les résidus dans chaque groupe sont indépendants et suivent une distribution normale avec la même variance.</p></li>
<li><p>Si l’hypothèse nulle de l’ANOVA est rejetée, on peut utiliser le test des étendues de Tukey pour identifier les différences significatives entre groupes.</p></li>
</ul>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
