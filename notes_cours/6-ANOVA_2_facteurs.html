<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>ANOVA à deux facteurs et blocs complets aléatoires</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/spacelab.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>
<link href="libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="fluid-row" id="header">



<h1 class="title toc-ignore">ANOVA à deux facteurs et blocs complets aléatoires</h1>
<h4 class="date"><br/>30 septembre 2019</h4>

</div>


<div id="objectifs" class="section level1">
<h1>Objectifs</h1>
<p>Lors du dernier cours, nous avons vu des exemples d’analyse de la variance (ANOVA) à un facteur. Dans ce cours, nous utiliserons l’ANOVA pour estimer l’effet additif de deux facteurs (deux variables catégorielles) ainsi que leur interaction. Nous étudierons aussi l’analyse des plans expérimentaux en blocs (blocs complets aléatoires).</p>
<p>Finalement, nous reformulerons le modèle d’ANOVA comme modèle de régression linéaire et nous verrons différentes options de codage des variables catégorielles (facteurs).</p>
</div>
<div id="rappel-anova-a-un-facteur" class="section level1">
<h1>Rappel: ANOVA à un facteur</h1>
<p>Dans le modèle d’ANOVA à un facteur, la réponse <span class="math inline">\(y_{ik}\)</span> de l’individu <span class="math inline">\(k\)</span> du groupe <span class="math inline">\(i\)</span> est la somme de trois effets: la réponse moyenne de la population en général (<span class="math inline">\(\mu\)</span>), la différence entre la moyenne du groupe <span class="math inline">\(i\)</span> et la moyenne générale (<span class="math inline">\(\alpha_i\)</span>) et le résidu (<span class="math inline">\(\epsilon_{ik}\)</span>) ou “erreur” qui constitue la partie de la réponse non-expliquée par le modèle.</p>
<p><span class="math display">\[ y_{ik} = \mu + \alpha_i + \epsilon_{ik} \]</span> Le modèle suppose aussi que les résidus sont indépendants et suivent la même distribution normale.</p>
<p><span class="math display">\[ \epsilon_{ik} \sim N(0, \sigma) \]</span></p>
</div>
<div id="anova-a-deux-facteurs-sans-interaction" class="section level1">
<h1>ANOVA à deux facteurs sans interaction</h1>
<p>Pour illustrer l’ANOVA à deux facteurs, nous utiliserons d’abord le jeu de données <a href="../donnees/growth.csv">growth.csv</a> provenant du manuel <em>Statistics: An Introduction Using R</em>. L’expérience compare le gain de poids (<em>gain</em>) de 48 animaux suivant trois types de régime alimentaire (<em>diet</em>) avec quatre types de suppléments (<em>supplement</em>). Il y a donc 12 groupes (toutes les combinaisons des 3 régimes et 4 suppléments) de 4 individus chacun.</p>
<pre class="r"><code>growth &lt;- read.csv(&quot;../donnees/growth.csv&quot;)
str(growth)</code></pre>
<pre><code>## &#39;data.frame&#39;:    48 obs. of  3 variables:
##  $ supplement: Factor w/ 4 levels &quot;agrimore&quot;,&quot;control&quot;,..: 3 3 3 3 2 2 2 2 4 4 ...
##  $ diet      : Factor w/ 3 levels &quot;barley&quot;,&quot;oats&quot;,..: 3 3 3 3 3 3 3 3 3 3 ...
##  $ gain      : num  17.4 16.8 18.1 15.8 17.7 ...</code></pre>
<pre class="r"><code>ggplot(growth, aes(x = supplement, y = gain, color = diet)) +
    # position_dodge décale les points de différentes couleurs
    geom_point(position = position_dodge(width = 0.3)) + 
    scale_color_brewer(palette = &quot;Dark2&quot;)</code></pre>
<p><img src="6-ANOVA_2_facteurs_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>Nous pourrions représenter cette expérience par le modèle suivant, où <span class="math inline">\(y_{ijk}\)</span> est le gain de poids pour l’individu <span class="math inline">\(k\)</span> suivant le régime <span class="math inline">\(i\)</span> avec un supplément <span class="math inline">\(j\)</span>:</p>
<p><span class="math display">\[ y_{ijk} = \mu + \alpha_i + \beta_j + \epsilon_{ijk} \]</span></p>
<p>Dans cette équation, <span class="math inline">\(\mu\)</span> est la moyenne générale, <span class="math inline">\(\alpha_i\)</span> représente l’effet du traitement <span class="math inline">\(i\)</span> du premier facteur (facteur A) et <span class="math inline">\(\beta_j\)</span> représente l’effet du traitrement <span class="math inline">\(j\)</span> du deuxième facteur (facteur B).</p>
<p>Remarquez que ce modèle est <strong>additif</strong>. Dans notre exemple, l’effet combiné d’un régime et d’un supplément est la somme des deux effets pris séparément. Nous verrons plus loin comment modéliser les effets non-additifs.</p>
<p>Les différents coefficients du modèle sont estimés ainsi (l’accent circonflexe représente l’estimation):</p>
<ul>
<li>Moyenne générale: <span class="math inline">\(\hat{\mu} = \bar{y}\)</span>.</li>
<li>Effet du traitement <span class="math inline">\(i\)</span> du facteur A: <span class="math inline">\(\hat{\alpha_i} = \bar{y_i} - \bar{y}\)</span> (différence entre la moyenne des individus obtenant le traitement <span class="math inline">\(i\)</span> et la moyenne générale).</li>
<li>Effet du traitement <span class="math inline">\(j\)</span> du facteur B: <span class="math inline">\(\hat{\beta_j} = \bar{y_j} - \bar{y}\)</span>.</li>
</ul>
<p>Les résidus sont sont égaux à <span class="math inline">\(y_{ijk} - \bar{y} - (\bar{y_i} - \bar{y}) - (\bar{y_j} - \bar{y})\)</span>, ou en simplifiant: <span class="math inline">\(y_{ijk} - \bar{y_i} - \bar{y_j} + \bar{y}\)</span>.</p>
<div id="tableau-danova-a-deux-facteurs-sans-interaction" class="section level2">
<h2>Tableau d’ANOVA à deux facteurs sans interaction</h2>
<p>Voici le tableau d’ANOVA correspondant à ce modèle si on a <span class="math inline">\(l\)</span> traitements du facteur A, <span class="math inline">\(m\)</span> traitements du facteur B et <span class="math inline">\(n\)</span> réplicats pour chaque combinaison des traitements (donc <span class="math inline">\(lmn\)</span> observations totales).</p>
<table style="width:100%;">
<colgroup>
<col width="5%" />
<col width="31%" />
<col width="31%" />
<col width="31%" />
</colgroup>
<thead>
<tr class="header">
<th>Composante</th>
<th>Somme des carrés (SS)</th>
<th>Degrés de liberté (df)</th>
<th>Carré moyen (MS)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Facteur A</td>
<td><span class="math inline">\(SSA = \sum_{i = 1}^l mn (\bar{y_i} - \bar{y})^2\)</span></td>
<td><span class="math inline">\(l - 1\)</span></td>
<td><span class="math inline">\(MSA = \frac{SSA}{l - 1}\)</span></td>
</tr>
<tr class="even">
<td>Facteur B</td>
<td><span class="math inline">\(SSB = \sum_{j = 1}^m ln (\bar{y_j} - \bar{y})^2\)</span></td>
<td><span class="math inline">\(m - 1\)</span></td>
<td><span class="math inline">\(MSB = \frac{SSB}{m - 1}\)</span></td>
</tr>
<tr class="odd">
<td>Résidu</td>
<td><span class="math inline">\(SSE = \sum_{i = 1}^l \sum_{j = 1}^m \sum_{k = i}^n (y_{ijk} - \bar{y_i} - \bar{y_j} + \bar{y})^2\)</span></td>
<td><span class="math inline">\(lmn - l - m + 1\)</span></td>
<td><span class="math inline">\(MSE = \frac{SSE}{lmn - l - m + 1}\)</span></td>
</tr>
<tr class="even">
<td>Total</td>
<td><span class="math inline">\(SST = \sum_{i = 1}^l \sum_{j = 1}^m \sum_{k = i}^n (y_{ijk} - \bar{y})^2\)</span></td>
<td><span class="math inline">\(lmn - 1\)</span></td>
<td></td>
</tr>
</tbody>
</table>
<p>Le nombre de degrés de liberté pour la moyenne des écarts résiduels (MSE) correspond toujours au nombre total d’observations, moins 1 degré de liberté par moyenne estimée (1 pour la moyenne générale, <span class="math inline">\(l - 1\)</span> pour les effets du facteur A et <span class="math inline">\(m - 1\)</span> pour les effets du facteur B).</p>
<p>Dans l’ANOVA à un facteur, le ratio <span class="math inline">\(MSA/MSE\)</span> était comparé à la distribution <span class="math inline">\(F\)</span> pour déterminer si le facteur A avait un effet significatif. Ici, deux tests <span class="math inline">\(F\)</span> indépendants sont réalisés à partir des ratios <span class="math inline">\(MSA/MSE\)</span> et <span class="math inline">\(MSB/MSE\)</span>, donc on obtient une valeur <span class="math inline">\(p\)</span> pour chacun des deux facteurs.</p>
</div>
<div id="exemple" class="section level2">
<h2>Exemple</h2>
<p>Dans R, un modèle à deux facteurs additifs est représenté par l’équation <code>reponse ~ facteurA + facteurB</code>.</p>
<pre class="r"><code>aov_growth_add &lt;- aov(gain ~ diet + supplement, data = growth)</code></pre>
<p>Vérifions d’abord les graphiques de diagnostic, puis les résultats sommaires de l’ANOVA.</p>
<p><img src="6-ANOVA_2_facteurs_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code>summary(aov_growth_add)</code></pre>
<pre><code>##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## diet         2 287.17  143.59   92.36 4.20e-16 ***
## supplement   3  91.88   30.63   19.70 3.98e-08 ***
## Residuals   42  65.30    1.55                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Les deux facteurs ont un effet très significatif. En regardant le résultat du test des étendues de Tukey, nous constatons que les trois régimes ont un effet différent (blé &lt; avoine &lt; orge). Pour les suppléments, <em>agrimore</em> et <em>supersupp</em> ont un effet plus grand que <em>supergain</em> et <em>control</em>.</p>
<pre class="r"><code>TukeyHSD(aov_growth_add)</code></pre>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = gain ~ diet + supplement, data = growth)
## 
## $diet
##                   diff       lwr       upr p adj
## oats-barley  -3.092817 -4.163817 -2.021817 0e+00
## wheat-barley -5.990298 -7.061298 -4.919297 0e+00
## wheat-oats   -2.897481 -3.968481 -1.826481 2e-07
## 
## $supplement
##                           diff        lwr        upr     p adj
## control-agrimore    -2.6967005 -4.0583332 -1.3350677 0.0000234
## supergain-agrimore  -3.3814586 -4.7430914 -2.0198259 0.0000003
## supersupp-agrimore  -0.7273521 -2.0889849  0.6342806 0.4888738
## supergain-control   -0.6847581 -2.0463909  0.6768746 0.5400389
## supersupp-control    1.9693484  0.6077156  3.3309811 0.0020484
## supersupp-supergain  2.6541065  1.2924737  4.0157392 0.0000307</code></pre>
</div>
<div id="coefficient-de-determination" class="section level2">
<h2>Coefficient de détermination</h2>
<p>Comme nous avons vu au dernier cours, la somme des écarts carrés entre chaque observation et la moyenne générale peut être décomposée en somme des écarts dûs aux traitements et aux effets résiduels. Pour l’ANOVA à deux facteurs, on a la relation: <span class="math inline">\(SST = SSA + SSB + SSE\)</span>. On peut donc interpréter les ratios <span class="math inline">\(SSA/SST\)</span> et <span class="math inline">\(SSB/SST\)</span> comme les fractions de la variance totale de la réponse expliquées par le facteur A et le facteur B, respectivement. Le ratio <span class="math inline">\(SSE/SST\)</span> est la fraction de la variance inexpliquée par le modèle (erreur résiduelle).</p>
<p>Dans notre exemple précédent, <span class="math inline">\(SST = 287.17 + 91.88 + 65.30 = 444.35\)</span>.</p>
<pre class="r"><code>summary(aov_growth_add)</code></pre>
<pre><code>##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## diet         2 287.17  143.59   92.36 4.20e-16 ***
## supplement   3  91.88   30.63   19.70 3.98e-08 ***
## Residuals   42  65.30    1.55                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>En calculant les ratios, on obtient 0.646 pour le facteur A, 0.207 pour le facteur B et 0.147 pour les résidus. Dans cette expérience, la plus grande partie de la variation en gain de poids est donc associée au changement de régime.</p>
<p>Puisque <span class="math inline">\(SSE/SST\)</span> est la fraction de la variance inexpliquée par le modèle, la fraction de la variance expliquée par les facteurs inclus dans le modèle est égale à:</p>
<p><span class="math display">\[ R^2 = 1 - \frac{SSE}{SST}\]</span></p>
<p>La valeur de <span class="math inline">\(R^2\)</span> se nomme <strong>coefficient de détermination</strong>. Dans l’exemple précédent, <span class="math inline">\(R^2 = 0.853\)</span>.</p>
<p>Dans le cours sur les tests d’hypothèse, il était recommandé de présenter trois types de résultats suite à un test:</p>
<ul>
<li>la probabilité que l’effet mesuré soit dû au hasard (valeur <span class="math inline">\(p\)</span>);</li>
<li>l’estimé et l’intervalle de confiance de l’effet mesuré; et</li>
<li>la magnitude de l’effet comparée à la variance des données individuelles.</li>
</ul>
<p>Le coefficient de détermination <span class="math inline">\(R^2\)</span> répond à la troisième question: Quelle partie de la variation observée est due à l’effet des traitements ou prédicteurs mesurés?</p>
<p>Finalement, un rappel: quand on parle de l’<em>effet</em> d’un prédicteur ou de la fraction de la variance <em>expliquée</em>, cela ne signifie pas toujours qu’il existe une relation de cause à effet entre le prédicteur et la réponse. Notre capacité à interpréter une association statistique (ou une corrélation) comme représentant un lien de cause à effet ne dépend pas de la magnitude de l’effet, mais plutôt des contrôles établis lors du plan expérimental: variation indépendante des facteurs, utilisation d’un groupe témoin, assignation aléatoire des traitements, etc.</p>
</div>
</div>
<div id="anova-a-deux-facteurs-avec-interaction" class="section level1">
<h1>ANOVA à deux facteurs avec interaction</h1>
<div id="exemple-1" class="section level2">
<h2>Exemple</h2>
<p>Le jeu de données <a href="../donnees/antibiot.csv">antibiot.csv</a> contient des mesures de prolifération bactérienne (surface couverte en mm<span class="math inline">\(^2\)</span>) en fonction de l’humidité (sec, humide) et de la concentration d’antibiotique (faible, modérée, élevée).</p>
<pre class="r"><code># fileEncoding = &quot;UTF-8&quot; permet de lire les accents correctement
antibiot &lt;- read.csv(&quot;../donnees/antibiot.csv&quot;, fileEncoding = &quot;UTF-8&quot;)
str(antibiot)</code></pre>
<pre><code>## &#39;data.frame&#39;:    30 obs. of  3 variables:
##  $ Surface      : num  2.1 2.73 1.86 2.36 2.2 ...
##  $ Humidité     : Factor w/ 2 levels &quot;humide&quot;,&quot;sec&quot;: 2 2 2 2 2 2 2 2 2 2 ...
##  $ Concentration: Factor w/ 3 levels &quot;élevée&quot;,&quot;faible&quot;,..: 2 2 2 2 2 3 3 3 3 3 ...</code></pre>
<p>Quand R importe un jeu de données avec <code>read.csv</code>, les colonnes non-numériques sont importées comme facteurs avec un ordre de catégories (ou de niveaux, <code>levels</code>) déterminé par l’ordre alphabétique.</p>
<pre class="r"><code>levels(antibiot$Concentration)</code></pre>
<pre><code>## [1] &quot;élevée&quot;  &quot;faible&quot;  &quot;modérée&quot;</code></pre>
<p>On peut spécifier un autre ordre avec la fonction <code>factor</code>.</p>
<pre class="r"><code>antibiot$Concentration &lt;- factor(antibiot$Concentration, 
                                 levels = c(&quot;faible&quot;, &quot;modérée&quot;, &quot;élevée&quot;))
levels(antibiot$Concentration)</code></pre>
<pre><code>## [1] &quot;faible&quot;  &quot;modérée&quot; &quot;élevée&quot;</code></pre>
<p>Voici le graphique de ces données. Est-ce qu’un modèle avec des effets additifs de la concentration d’antibiotique et de l’humidité serait approprié ici?</p>
<pre class="r"><code>ggplot(antibiot, aes(x = Concentration, y = Surface, color = Humidité)) +
    geom_point(position = position_dodge(width = 0.3)) + 
    scale_color_brewer(palette = &quot;Dark2&quot;)</code></pre>
<p><img src="6-ANOVA_2_facteurs_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>Ici, il y a une <em>interaction</em> claire entre les deux facteurs. Notamment, les conditions humides sont associées à une plus grande surface bactérienne pour les concentrations faible et modérée d’antibiotiques, mais les conditions sèches ont une plus grande surface bactérienne lorsque la concentration est élevée.</p>
</div>
<div id="estimation-de-linteraction" class="section level2">
<h2>Estimation de l’interaction</h2>
<p>Pour représenter l’interaction entre les deux facteurs, on ajoute un terme <span class="math inline">\(\gamma_ij\)</span> au modèle d’ANOVA.</p>
<p><span class="math display">\[ y_{ijk} = \mu + \alpha_i + \beta_j + \gamma_{ij} + \epsilon_{ijk} \]</span></p>
<p>L’effet de l’interaction <span class="math inline">\(\gamma_ij\)</span> est la différence entre l’effet moyen des traitements <span class="math inline">\(i\)</span> et <span class="math inline">\(j\)</span> appliqués ensemble, et la somme des effet moyens de ces deux traitements pris séparément. Cet effet est estimé comme suit à partir des moyennes.</p>
<p><span class="math display">\[ \hat{\gamma_{ij}} = (\bar{y_{ij}} - \bar{y}) - (\bar{y_i} - \bar{y}) - (\bar{y_j} - \bar{y}) \]</span> En simplifiant: <span class="math display">\[ \hat{\gamma_{ij}} = \bar{y_{ij}} - \bar{y_i} - \bar{y_j} + \bar{y} \]</span></p>
<p>Dans cette équation, <span class="math inline">\(\bar{y_{ij}}\)</span> est la moyenne des observations qui font partie à la fois du groupe <span class="math inline">\(i\)</span> du facteur A et du groupe <span class="math inline">\(j\)</span> du facteur B. Le résidu du modèle pour une observation <span class="math inline">\(y_{ijk}\)</span> est égal à <span class="math inline">\(y_{ijk} - \bar{y_{ij}}\)</span>.</p>
<p>En incluant l’interaction, le tableau d’ANOVA à deux facteurs prend la forme suivante:</p>
<table style="width:100%;">
<colgroup>
<col width="5%" />
<col width="31%" />
<col width="31%" />
<col width="31%" />
</colgroup>
<thead>
<tr class="header">
<th>Composante</th>
<th>Somme des carrés (SS)</th>
<th>Degrés de liberté (df)</th>
<th>Carré moyen (MS)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Facteur A</td>
<td><span class="math inline">\(SSA = \sum_{i = 1}^l mn (\bar{y_i} - \bar{y})^2\)</span></td>
<td><span class="math inline">\(l - 1\)</span></td>
<td><span class="math inline">\(MSA = \frac{SSA}{l - 1}\)</span></td>
</tr>
<tr class="even">
<td>Facteur B</td>
<td><span class="math inline">\(SSB = \sum_{j = 1}^m ln (\bar{y_j} - \bar{y})^2\)</span></td>
<td><span class="math inline">\(m - 1\)</span></td>
<td><span class="math inline">\(MSB = \frac{SSB}{m - 1}\)</span></td>
</tr>
<tr class="odd">
<td>Interaction AB</td>
<td><span class="math inline">\(SSI = \sum_{i = 1}^l \sum_{j = 1}^m n (\bar{y_{ij}} - \bar{y_i} - \bar{y_j} + \bar{y})^2\)</span></td>
<td><span class="math inline">\((l - 1)(m - 1)\)</span></td>
<td><span class="math inline">\(MSI = \frac{SSI}{(l-1)(m-1)}\)</span></td>
</tr>
<tr class="even">
<td>Résidu</td>
<td><span class="math inline">\(SSE = \sum_{i = 1}^l \sum_{j = 1}^m \sum_{k = i}^n (y_{ijk} - \bar{y_{ij}})^2\)</span></td>
<td><span class="math inline">\(lm(n - 1)\)</span></td>
<td><span class="math inline">\(MSE = \frac{SSE}{lm(n-1)}\)</span></td>
</tr>
<tr class="odd">
<td>Total</td>
<td><span class="math inline">\(SST = \sum_{i = 1}^l \sum_{j = 1}^m \sum_{k = i}^n (y_{ijk} - \bar{y})^2\)</span></td>
<td><span class="math inline">\(lmn - 1\)</span></td>
<td></td>
</tr>
</tbody>
</table>
<p>Le nombre de degrés de liberté pour l’interaction est le produit du nombre de degrés de liberté de chaque facteur. L’interaction a sa propre statistique <span class="math inline">\(F\)</span> égale au ratio <span class="math inline">\(MSI/MSE\)</span>. L’hypothèse nulle correspond à l’absence d’interaction, c’est-à-dire que les effets des deux facteurs sont additifs et que tous les <span class="math inline">\(\gamma_{ij}\)</span> sont de 0.</p>
</div>
<div id="application" class="section level2">
<h2>Application</h2>
<p>En R, pour spécifier une interaction dans la formule du modèle, on place un symbole de multiplication <code>*</code> entre les deux variables au lieu du <code>+</code>.</p>
<pre class="r"><code>aov_antibio &lt;- aov(Surface ~ Concentration * Humidité, antibiot)</code></pre>
<p>Voici les graphiques et le tableau sommaire de ce modèle:</p>
<p><img src="6-ANOVA_2_facteurs_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<pre class="r"><code>summary(aov_antibio)</code></pre>
<pre><code>##                        Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## Concentration           2  15.93   7.965    71.5 7.76e-11 ***
## Humidité                1  20.23  20.228   181.6 1.09e-12 ***
## Concentration:Humidité  2  36.40  18.199   163.4 1.05e-14 ***
## Residuals              24   2.67   0.111                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>L’interaction entre les 3 catégories de concentration et les 2 catégories d’humidité définit 6 groupes, donc il y a 15 comparaisons possibles pour l’interaction, comme le montre le résultat de <code>TukeyHSD</code>.</p>
<pre class="r"><code>TukeyHSD(aov_antibio)</code></pre>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = Surface ~ Concentration * Humidité, data = antibiot)
## 
## $Concentration
##                      diff        lwr         upr     p adj
## modérée-faible -0.3939894 -0.7667378 -0.02124113 0.0368807
## élevée-faible  -1.7046765 -2.0774249 -1.33192823 0.0000000
## élevée-modérée -1.3106871 -1.6834354 -0.93793878 0.0000000
## 
## $Humidité
##                 diff       lwr       upr p adj
## sec-humide -1.642264 -1.893794 -1.390734     0
## 
## $`Concentration:Humidité`
##                                     diff          lwr        upr     p adj
## modérée:humide-faible:humide -0.82921989 -1.481887432 -0.1765523 0.0073592
## élevée:humide-faible:humide  -4.22827694 -4.880944489 -3.5756094 0.0000000
## faible:sec-faible:humide     -3.61481768 -4.267485222 -2.9621501 0.0000000
## modérée:sec-faible:humide    -3.57357668 -4.226244229 -2.9209091 0.0000000
## élevée:sec-faible:humide     -2.79589383 -3.448561371 -2.1432263 0.0000000
## élevée:humide-modérée:humide -3.39905706 -4.051724600 -2.7463895 0.0000000
## faible:sec-modérée:humide    -2.78559779 -3.438265333 -2.1329302 0.0000000
## modérée:sec-modérée:humide   -2.74435680 -3.397024340 -2.0916893 0.0000000
## élevée:sec-modérée:humide    -1.96667394 -2.619341482 -1.3140064 0.0000000
## faible:sec-élevée:humide      0.61345927 -0.039208277  1.2661268 0.0740073
## modérée:sec-élevée:humide     0.65470026  0.002032716  1.3073678 0.0489732
## élevée:sec-élevée:humide      1.43238312  0.779715574  2.0850507 0.0000070
## modérée:sec-faible:sec        0.04124099 -0.611426550  0.6939085 0.9999549
## élevée:sec-faible:sec         0.81892385  0.166256308  1.4715914 0.0082690
## élevée:sec-modérée:sec        0.77768286  0.125015314  1.4303504 0.0131278</code></pre>
<p>Dans le cas du jeu de données sur la croissance animale <code>growth</code>, l’interaction n’est pas significative:</p>
<pre class="r"><code>aov_growth_inter &lt;- aov(gain ~ diet * supplement, growth)
summary(aov_growth_inter)</code></pre>
<pre><code>##                 Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## diet             2 287.17  143.59   83.52 3.00e-14 ***
## supplement       3  91.88   30.63   17.82 2.95e-07 ***
## diet:supplement  6   3.41    0.57    0.33    0.917    
## Residuals       36  61.89    1.72                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Doit-on toujours estimer l’interaction dans un modèle d’ANOVA à deux facteurs? Le principal désavantage du modèle avec interaction est qu’il faut estimer plus de paramètres. En particulier, puisqu’on estime la moyenne de chaque combinaison des deux facteurs, il faut un nombre suffisant d’observations avec la même valeur des deux facteurs (réplicats). Les jeux de données montrés en exemple comptent 4 ou 5 réplicats par combinaison des deux facteurs, ce qui un peu faible comme taille d’échantillon dans ce cas. Notez qu’il est impossible d’estimer l’interaction s’il n’y a qu’une observation pour chaque combinaison de facteurs.</p>
</div>
</div>
<div id="experience-par-blocs" class="section level1">
<h1>Expérience par blocs</h1>
<p>Lors du cours sur les plans expérimentaux, nous avons discuté de l’utilité des expériences par blocs complets aléatoires. Dans ce type de plan, les unités d’observation sont divisées en blocs où les conditions dans chaque bloc sont plus homogènes, puis les traitements sont assignés aléatoirement dans chaque bloc. Il s’agit de l’équivalent d’une expérience à échantillons appariés pour plus de deux traitements.</p>
<p>Le fichier <a href="../donnees/pigs.csv">pigs.csv</a> contient les résultats d’une expérience mesurant le poids (<em>Weight</em>) de cobayes selon quatre régimes alimentaires (<em>Diet</em>). Les vingt individus sont divisés en cinq blocs (<em>Block</em>) qui pourraient représenter par exemple des cobayes provenant de la même portée.</p>
<pre class="r"><code>pigs &lt;- read.csv(&quot;../donnees/pigs.csv&quot;)
str(pigs)</code></pre>
<pre><code>## &#39;data.frame&#39;:    20 obs. of  3 variables:
##  $ Block : int  1 1 1 1 2 2 2 2 3 3 ...
##  $ Diet  : int  1 2 3 4 1 2 3 4 1 2 ...
##  $ Weight: num  1.5 2.7 2.1 1.3 1.4 2.9 2.2 1 1.4 2.1 ...</code></pre>
<p>Dans ce jeu de données, <em>Block</em> et <em>Diet</em> sont des variables catégorielles même si elles sont représentées par des nombres. Il faut donc convertir ces variables en facteurs dans R avec l’instruction <code>as.factor</code>.</p>
<pre class="r"><code>pigs &lt;- mutate(pigs, Block = as.factor(Block), Diet = as.factor(Diet))</code></pre>
<p>Le modèle mathématique que nous utiliserons ici est le même que pour l’ANOVA à deux facteurs, sans interaction. On ne pourrait pas estimer l’interaction ici, vu qu’il n’y a qu’une observation par combinaison de bloc et de régime. Nous devons donc supposer que les effets sont additifs: chaque bloc a un poids moyen différent, mais l’effet de chaque régime est le même pour tous les blocs.</p>
<pre class="r"><code>aov_pigs &lt;- aov(Weight ~ Diet + Block, data = pigs)</code></pre>
<p><img src="6-ANOVA_2_facteurs_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<pre class="r"><code>summary(aov_pigs)</code></pre>
<pre><code>##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## Diet         3  8.154  2.7178  41.866 1.24e-06 ***
## Block        4  0.393  0.0982   1.513     0.26    
## Residuals   12  0.779  0.0649                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Même si le modèle est identique à celui de l’ANOVA à deux facteurs, l’interprétation est différente. Dans ce cas-ci, nous ne nous intéressons pas à estimer l’effet des blocs. La structure de blocs vise à réduire la variabilité à l’intérieur des blocs, donc la portion résiduelle de la variance, et ainsi faciliter la détection de l’effet des traitements (régimes).</p>
<div id="effets-fixes-ou-aleatoires" class="section level2">
<h2>Effets fixes ou aléatoires</h2>
<p>Dans le modèle ci-dessus, les effets des blocs sont des <strong>effets fixes</strong>, c’est-à-dire qu’ils sont estimés séparément pour chaque bloc. (Les effets de traitement sont aussi fixes.) Dans certains problèmes d’observations groupées, il est préférable de considérer les moyennes de chaque bloc comme provenant elles-mêmes d’une distribution, et d’estimer les paramètres de cette distribution plutôt que la moyenne de chaque bloc individuellement. Nous inclurons ce type d’<strong>effets aléatoires</strong> dans la partie du cours sur les modèles mixtes, plus tard dans la session.</p>
</div>
</div>
<div id="regression-lineaire-et-contrastes" class="section level1">
<h1>Régression linéaire et contrastes</h1>
<p>Le modèle d’ANOVA est un exemple de régression linéaire, donc la même forme de modèle peut être analysée avec la fonction <code>lm</code> dans R. Par exemple, considérons l’effet du supplément sur le gain de poids (un seul facteur) dans le jeu de données <code>growth</code>.</p>
<pre class="r"><code>lm_growth_supp &lt;- lm(gain ~ supplement, data = growth)</code></pre>
<p>Le tableau de résultats pour <code>lm</code> met davantage l’accent sur l’estimation des effets (dans la section <em>Coefficients</em>).</p>
<pre class="r"><code>summary(lm_growth_supp)</code></pre>
<pre><code>## 
## Call:
## lm(formula = gain ~ supplement, data = growth)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.1309 -2.2142 -0.2459  1.7644  5.9339 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)          23.0953     0.8170  28.267  &lt; 2e-16 ***
## supplementcontrol    -2.6967     1.1555  -2.334  0.02423 *  
## supplementsupergain  -3.3815     1.1555  -2.926  0.00541 ** 
## supplementsupersupp  -0.7274     1.1555  -0.629  0.53228    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.83 on 44 degrees of freedom
## Multiple R-squared:  0.2068, Adjusted R-squared:  0.1527 
## F-statistic: 3.823 on 3 and 44 DF,  p-value: 0.01614</code></pre>
<p>Avant de discuter des coefficients, regardons les valeurs au bas du tableau. L’erreur-type résiduelle est la racine carré de la <em>MSE</em> (la moyenne des écarts carrés résiduels) du tableau d’ANOVA. La valeur <code>Mutipled R-squared</code> correspond au coefficient de détermination <span class="math inline">\(R^2\)</span> définit plus tôt. La valeur <code>Adjusted R-squared</code> a une définition légèrement différente; elle est basée sur la ratio entre la <em>MSE</em> et la variance totale, plutôt que le ratio des sommes des carrés <em>SSE</em> et <em>SST</em>. Finalement, le test <span class="math inline">\(F\)</span> de la dernière ligne (avec sa valeur <span class="math inline">\(p\)</span>) correspond à celui de l’ANOVA à un facteur. On peut retrouver le tableau d’ANOVA en appliquant la fonction <code>anova</code> au résultat de <code>lm</code>.</p>
<pre class="r"><code>anova(lm_growth_supp)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: gain
##            Df Sum Sq Mean Sq F value  Pr(&gt;F)  
## supplement  3  91.88 30.6270  3.8233 0.01614 *
## Residuals  44 352.47  8.0106                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>L’ajustement du modèle linéaire avec <code>lm</code> produit ici quatre coefficients: <code>(Intercept)</code>, <code>supplementcontrol</code>, <code>supplementsupergain</code> et <code>supplementsupersupp</code>. Comme nous avons brièvement mentionné au dernier cours, la valeur <code>(Intercept)</code>correspond à la moyenne de la réponse pour la première catégorie du facteur <code>supplement</code>, soit <code>agrimore</code>, et les autres coefficients correspondent à la différence de moyenne entre chacune des trois autres catégories et <code>agrimore</code>. Dans les prochaines sections, nous verrons pourquoi les facteurs sont codés ainsi et comment modifier ce codage.</p>
<div id="codage-dune-variable-categorielle" class="section level2">
<h2>Codage d’une variable catégorielle</h2>
<p>L’équation suivante décrit un modèle linéaire pour la relation entre un prédicteur numérique <span class="math inline">\(x\)</span> et une réponse numérique <span class="math inline">\(y\)</span>. La valeur de <span class="math inline">\(y\)</span> dépend d’un terme constant (<span class="math inline">\(\beta_0\)</span>), d’un terme proportionnel à <span class="math inline">\(x\)</span> (<span class="math inline">\(\beta_1 x\)</span>) et d’un résidu aléatoire pour chaque observation (<span class="math inline">\(\epsilon\)</span>).</p>
<p><span class="math display">\[ y = \beta_0 + \beta_1 x + \epsilon \]</span></p>
<p>Dans ce cas, <span class="math inline">\(\beta_0\)</span> est l’ordonnée à l’origine (en anglais, <em>intercept</em>) du graphique de <span class="math inline">\(y\)</span> vs. <span class="math inline">\(x\)</span>, la valeur moyenne de <span class="math inline">\(y\)</span> lorsque <span class="math inline">\(x = 0\)</span>.</p>
<p>Imaginons une expérience avec un groupe témoin et deux traitements (<span class="math inline">\(T_1\)</span> et <span class="math inline">\(T_2\)</span>). Pour représenter ces données dans un modèle de régression, nous créons deux variables:</p>
<ul>
<li><span class="math inline">\(T_1\)</span> = 1 pour les observations qui ont reçu le traitement 1, 0 pour les autres.</li>
<li><span class="math inline">\(T_2\)</span> = 1 pour les observations qui ont reçu le traitement 2, 0 pour les autres.</li>
</ul>
<p>Nous obtenons donc le modèle: <span class="math inline">\(y = \beta_0 + \beta_1 T_1 + \beta_2 T_2 + \epsilon\)</span></p>
<p>En remplaçant les valeurs de <span class="math inline">\(T_1\)</span> et <span class="math inline">\(T_2\)</span>, nous pouvons déterminer la moyenne de <span class="math inline">\(y\)</span> pour chacun des groupes selon les coefficients <span class="math inline">\(\beta\)</span>:</p>
<ul>
<li>Groupe témoin (<span class="math inline">\(T_1 = 0, T_2 = 0\)</span>): <span class="math inline">\(\mu_{tém} = \beta_0\)</span></li>
<li>Traitement 1 (<span class="math inline">\(T_1 = 1, T_2 = 0\)</span>): <span class="math inline">\(\mu_{tr1} = \beta_0 + \beta_1\)</span></li>
<li>Traitement 2 (<span class="math inline">\(T_1 = 0, T_2 = 1\)</span>): <span class="math inline">\(\mu_{tr2} = \beta_0 + \beta_2\)</span></li>
</ul>
<p>L’ordonnée à l’origine correspond à la moyenne du groupe témoin tandis que les deux autres coefficients représentent la différence entre la moyenne de chaque traitement et celle du groupe témoin. Ce type de codage d’une variable catégorielle permet de comparer facilement chaque traitement à un traitement de référence. C’est le type de codage utilisé par défaut dans R, comme nous avons vu dans les résultats ci-dessus.</p>
</div>
<div id="contrastes" class="section level2">
<h2>Contrastes</h2>
<p>En statistiques, un <em>contraste</em> est une variable numérique définie à partir d’un variable catégorielle (ou facteur) qui représente une comparaison entre catégories.</p>
<p>Pour un facteur avec <span class="math inline">\(k\)</span> catégories, on peut définir <span class="math inline">\(k - 1\)</span> contrastes indépendants. Dans l’exemple précédent, les contrastes <span class="math inline">\(T_1\)</span> et <span class="math inline">\(T_2\)</span> servaient à comparer le traitement 1 au groupe témoin et le traitement 2 au groupe témoin. En connaissant ces deux différences, on connait aussi la différence entre les traitements 1 et 2, donc il serait redondant d’ajouter un troisième contraste.</p>
<p>Dans R, la fonction <code>contrasts</code> affiche la matrice des contrastes associés à un facteur.</p>
<pre class="r"><code>contrasts(growth$supplement)</code></pre>
<pre><code>##           control supergain supersupp
## agrimore        0         0         0
## control         1         0         0
## supergain       0         1         0
## supersupp       0         0         1</code></pre>
<p>Les colonnes de cette matrice correspondent aux contrastes (<code>control</code>, <code>supergain</code> et <code>supersupp</code>) qui prennent une valeur de 1 pour un des traitements et 0 pour les autres. Le premier traitement <code>agrimore</code> est associé à un valeur 0 pour chacun des contrastes. Dans ce cas-ci, il serait préférable d’utiliser le groupe témoin (<code>control</code>) comme référence. Nous pouvons changer le niveau de référence avec la fonction <code>relevel</code>.</p>
<pre class="r"><code>growth$supplement &lt;- relevel(growth$supplement, ref = &quot;control&quot;)
contrasts(growth$supplement)</code></pre>
<pre><code>##           agrimore supergain supersupp
## control          0         0         0
## agrimore         1         0         0
## supergain        0         1         0
## supersupp        0         0         1</code></pre>
<p>En ré-estimant le modèle linéaire avec ces nouveaux contrastes, on obtient des coefficients indiquant la différence entre chaque supplément et le groupe témoin.</p>
<pre class="r"><code>lm_growth_supp &lt;- lm(gain ~ supplement, data = growth)
summary(lm_growth_supp)</code></pre>
<pre><code>## 
## Call:
## lm(formula = gain ~ supplement, data = growth)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.1309 -2.2142 -0.2459  1.7644  5.9339 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)          20.3986     0.8170  24.967   &lt;2e-16 ***
## supplementagrimore    2.6967     1.1555   2.334   0.0242 *  
## supplementsupergain  -0.6848     1.1555  -0.593   0.5565    
## supplementsupersupp   1.9693     1.1555   1.704   0.0954 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.83 on 44 degrees of freedom
## Multiple R-squared:  0.2068, Adjusted R-squared:  0.1527 
## F-statistic: 3.823 on 3 and 44 DF,  p-value: 0.01614</code></pre>
<p>Notez que le changement de contrastes n’affecte que l’estimation des coefficients. La valeur du <span class="math inline">\(R^2\)</span> et du test <span class="math inline">\(F\)</span> sont les mêmes.</p>
<p>Pour chaque coefficient, le tableau inclut le résultat d’un test <span class="math inline">\(t\)</span> qui indique si chaque coefficient est significativement différent de 0. Ici, un seul des trois suppléments (agrimore) a un effet significatif si on choisit un seuil de 0.05. Cependant, ces résultats sont basés sur des tests <span class="math inline">\(t\)</span> indépendants qui ne tiennent pas compte des comparaisons multiples. Ils ne sont donc pas aussi fiables que le test des étendues de Tukey vu au cours précédent.</p>
</div>
<div id="interpretation-des-coefficients-pour-deux-facteurs" class="section level2">
<h2>Interprétation des coefficients pour deux facteurs</h2>
<p>Ajoutons maintenant la variable <code>diet</code> à notre régression.</p>
<pre class="r"><code>lm_growth &lt;- lm(gain ~ diet + supplement, data = growth)
summary(lm_growth)</code></pre>
<pre><code>## 
## Call:
## lm(formula = gain ~ diet + supplement, data = growth)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.30792 -0.85929 -0.07713  0.92052  2.90615 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)          23.4263     0.4408  53.141  &lt; 2e-16 ***
## dietoats             -3.0928     0.4408  -7.016 1.38e-08 ***
## dietwheat            -5.9903     0.4408 -13.589  &lt; 2e-16 ***
## supplementagrimore    2.6967     0.5090   5.298 4.03e-06 ***
## supplementsupergain  -0.6848     0.5090  -1.345 0.185772    
## supplementsupersupp   1.9693     0.5090   3.869 0.000375 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.247 on 42 degrees of freedom
## Multiple R-squared:  0.8531, Adjusted R-squared:  0.8356 
## F-statistic: 48.76 on 5 and 42 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Avant de discuter des contrastes pour le facteur <code>diet</code>, remarquez les différences entre ce tableau et celui de la régression précédente. Les coefficients associés aux différents suppléments sont les mêmes, mais les valeur <span class="math inline">\(p\)</span> sont beaucoup plus faibles. Pourquoi l’effet est-il plus significatif dans ce cas?</p>
<p>En ajoutant la variable <code>diet</code>, nous sommes capables d’expliquer une plus grande partie de la réponse (le <span class="math inline">\(R^2\)</span> est passé de 0.2 à 0.8 environ) et la variation résiduelle est plus petite. C’est pourquoi l’erreur-type des coefficients est plus faible et leur valeur est donc plus significativement différente de zéro.</p>
<p>Voici les contrastes pour le facteur <code>diet</code>:</p>
<pre class="r"><code>contrasts(growth$diet)</code></pre>
<pre><code>##        oats wheat
## barley    0     0
## oats      1     0
## wheat     0     1</code></pre>
<p>Si les coefficients des différents suppléments sont les mêmes, la valeur de l’ordonnée à l’origine <code>Intercept</code> a changé entre les deux tableaux (23.4 au lieu de 20.4). L’ordonnée à l’origine correspond au cas où tous les contrastes sont 0. Dans le modèle à un facteur, ce coefficient représentait la moyenne du groupe témoin, indépendamment du régime. Maintenant, il représente la moyenne des observations du groupe témoin (valeur de référence de <code>supplement</code>) qui ont le régime <code>barley</code> (valeur de référence pour <code>diet</code>).</p>
</div>
<div id="modifier-le-type-de-contrastes" class="section level2">
<h2>Modifier le type de contrastes</h2>
<p>Le type de contrastes utilisé par défaut dans R compare chaque catégorie à une catégorie de référence. On dit qu’il s’agit d’un codage de traitement (<code>contr.treatment</code> dans R) car il est utile pour comparer des traitements à un groupe témoin. Puisque nous n’avons pas de groupe de référence pour le facteur <code>diet</code>, nous pourrions utiliser un autre type de contraste. Voici des contrastes de type <code>contr.sum</code> (codage d’effet) pour la même variable.</p>
<pre class="r"><code>contrasts(growth$diet) &lt;- &quot;contr.sum&quot;
contrasts(growth$diet)</code></pre>
<pre><code>##        [,1] [,2]
## barley    1    0
## oats      0    1
## wheat    -1   -1</code></pre>
<p>Pour plus facilement interpréter les résultats, nous pouvons assigner un nom aux variables de contraste.</p>
<pre class="r"><code>colnames(contrasts(growth$diet)) &lt;- c(&quot;barley&quot;, &quot;oats&quot;)</code></pre>
<p>Dans ce type de codage, chaque contraste prend la valeur de 1 pour une des catégories, sauf la dernière catégorie qui prend une valeur de -1 pour tous les contrastes. Une propriété importante de ces contrastes est que la somme de chaque colonne est zéro, ce qui signifie que la moyenne de chaque contraste sur l’ensemble des catégories est zéro.</p>
<blockquote>
<p>Au sens strict utilisé en statistiques, une variable de contraste doit avoir une somme de zéro sur l’ensemble des catégories. Le codage de traitement utilisé par défaut dans R ne forme donc pas des vrais contrastes.</p>
</blockquote>
<p>Reprenons le modèle de régression: <span class="math inline">\(y = \beta_0 + \beta_1 T_1 + \beta_2 T_2\)</span> avec le codage d’effet défini ci-dessus.</p>
<ul>
<li>Catégorie 1 (<span class="math inline">\(T_1 = 1, T_2 = 0\)</span>): <span class="math inline">\(\mu_1 = \beta_0 + \beta_1\)</span></li>
<li>Catégorie 2 (<span class="math inline">\(T_1 = 0, T_2 = 1\)</span>): <span class="math inline">\(\mu_2 = \beta_0 + \beta_2\)</span></li>
<li>Catégorie 3 (<span class="math inline">\(T_1 = -1, T_2 = -1\)</span>): <span class="math inline">\(\mu_3 = \beta_0 - \beta_1 - \beta_2\)</span></li>
<li>Moyenne générale: <span class="math inline">\(\mu = (\mu_1 + \mu_2 + \mu_3)/3 = \beta_0\)</span></li>
</ul>
<p>L’ordonnée à l’origine correspond donc à la moyenne générale tandis que les coefficients correspondent à la différence entre la moyenne de chaque catégorie et la moyenne générale. L’effet de la dernière catégorie peut être déterminé en prenant l’opposé de la somme des autres effets, donc <span class="math inline">\(-(\beta_1 + \beta_2)\)</span> ici.</p>
<p>Voici le résultat de la régression linéaire avec ces nouveaux contrastes.</p>
<pre class="r"><code>lm_growth &lt;- lm(gain ~ diet + supplement, data = growth)
summary(lm_growth)</code></pre>
<pre><code>## 
## Call:
## lm(formula = gain ~ diet + supplement, data = growth)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.30792 -0.85929 -0.07713  0.92052  2.90615 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         20.39861    0.35994  56.673  &lt; 2e-16 ***
## dietbarley           3.02770    0.25451  11.896 4.93e-15 ***
## dietoats            -0.06511    0.25451  -0.256 0.799333    
## supplementagrimore   2.69670    0.50903   5.298 4.03e-06 ***
## supplementsupergain -0.68476    0.50903  -1.345 0.185772    
## supplementsupersupp  1.96935    0.50903   3.869 0.000375 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.247 on 42 degrees of freedom
## Multiple R-squared:  0.8531, Adjusted R-squared:  0.8356 
## F-statistic: 48.76 on 5 and 42 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><strong>Question</strong>: Que signifient les coefficients dans ce tableau? Quel est l’effet du troisième régime (<code>wheat</code>)?</p>
<p><strong>Réponse</strong>:</p>
<ul>
<li>Les coefficients <code>dietbarley</code> et <code>dietoats</code> donnent l’effet de ce régime par rapport à la moyenne des régimes.</li>
<li>Les trois coefficients de supplément donnent l’effet de ce supplément par rapport au groupe témoin (<code>control</code>).</li>
<li>L’ordonnée à l’origine est la moyenne du gain de poids du groupe témoin (moyenne des trois régimes).</li>
<li>L’effet du régime <code>wheat</code> par rapport à la moyenne est d’environ -2.96 (-(3.028 - 0.065)).</li>
</ul>
<p>Remarquez qu’il est possible d’utiliser différents codages pour différents facteurs dans la même régression. Le codage de traitement (défaut) est utile pour comparer les catégories à une catégorie de référence, tandis que le codage d’effet (<code>contr.sum</code>) est utile pour comparer le catégories à la réponse moyenne.</p>
<p>Si les deux facteurs avaient un codage d’effet, l’ordonnée à l’origine serait égale à la moyenne générale (tous les régimes et suppléments).</p>
</div>
</div>
<div id="resume" class="section level1">
<h1>Résumé</h1>
<ul>
<li><p>L’ANOVA à deux facteurs permet d’évaluer l’effet de deux variables catégorielles (ex.: deux types de traitement) et de déterminer si ces effets sont additifs ou s’il y a une interaction.</p></li>
<li><p>Une expérience à blocs complets aléatoires s’analyse comme une ANOVA à deux facteurs sans interaction. La division en blocs permet de contrôler une partie de la variation pour mieux estimer l’effet des traitements.</p></li>
<li><p>Le modèle d’ANOVA est un exemple de régression linéaire. Les variables catégorielles sont représentées dans un modèle de régression au moyen de contrastes.</p></li>
<li><p>Nous avons vu deux des types de contrastes possibles dans R: le codage de traitement (option par défaut) compare l’effet de chaque catégorie à une catégorie de référence, tandis que le codage d’effet compare l’effet de chaque catégorie à la moyenne de toutes les catégories.</p></li>
</ul>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
